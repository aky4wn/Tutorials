{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Variational Inference\n",
    "\n",
    "Variational Inference (VI) is a method for approximating the posterior in Bayesian models. Instead of sampling via Markov Chain Monte Carlo (MCMC) to approximate an intractable posterior, Variational Inference performs optimization. \n",
    "\n",
    "For a restricted set of distributions, Variational Inference finds the distribution in that set that is closest to the true posterior in terms of the KL divergence.  The goal is  to only consider tractable distributions, while still allowing for enough flexibility to obtain a distribution that approximates the true posterior well. \n",
    "\n",
    "Variational inference can be faster than MCMC methods and tends to scale well.  As a result, different forms of Variational Inference are commonly used in modern machine learning methods to perform Bayesian inference. \n",
    "\n",
    "The derivations and layout follow *Pattern Recognition and Machine Learning* by Chris Bishop (https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $X$ represent the observed variables, and $Z$ represent the latent variables and the parameters.  Let $p$ represent the true posterior and assume that we want to approximate $p$ with a more tractable distribution, $q$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming a form of the approximate posterior, we want to find the  distribution $q$ that is \"closest\" to the true posterior $p$. We can measure the \"closeness\" of distributions in terms of the KL divergence (https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence). \n",
    "\n",
    "For a given distribution $q$, we can write the log likelihood of the observed data as:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\log p(x) &= \\sum_z q(z) \\log p(X) \\\\\n",
    "&= \\sum_z q(z) \\log\\left(\\dfrac{p(X, Z)}{p(Z|X)}\\right) \\\\\n",
    "&= \\sum_z q(z) \\log\\left(\\dfrac{p(X, Z)}{p(Z|X)}\\dfrac{q(Z)}{q(Z)}\\right) \\\\\n",
    "&= \\sum_z q(z) \\left(\\log\\left(\\dfrac{p(X, Z)}{q(Z)}\\right) + \\log\\left(\\dfrac{q(Z)}{p(Z|X)}\\right)\\right) \\\\\n",
    "&= \\sum_z q(z) \\left(\\log\\left(\\dfrac{p(X, Z)}{q(Z)}\\right) - \\log\\left(\\dfrac{p(Z|X}{q(Z)}\\right)\\right) \\\\\n",
    "&= \\sum_z q(Z) \\log\\left(\\dfrac{p(X, Z)}{q(Z)}\\right) - \\sum_z q(z) \\log\\left(\\dfrac{p(Z|X)}{q(Z)}\\right) \\\\\n",
    "\\log p(X) &= L(q) + KL(q||p) \\\\\n",
    "L(q) &= \\sum_z q(Z) \\log\\left(\\dfrac{p(X, Z)}{q(Z)}\\right) \\\\\n",
    "KL(q||p) &= - \\sum_z q(Z) \\log\\left(\\dfrac{p(Z|X)}{q(Z)}\\right) \n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More generally, we have that \n",
    "\\begin{aligned}\n",
    "\\log p(X) &= L(q) + KL(q||p) \\\\\n",
    "L(q) &= \\int q(Z) \\log\\left(\\dfrac{p(X, Z)}{q(Z)}\\right)dZ \\\\\n",
    "KL(q||p) &= - \\int q(Z) \\log\\left(\\dfrac{p(Z|X)}{q(Z)}\\right)dZ \n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that minimizing $KL(q||p)$ is equivalent to maximizing $L(q)$.  That is, for a choice of family of distributions $q$, variational inference finds the specific distribution that maximizes $L(q)$, and is thus the closest member of the approximate family to the true posterior in terms of the KL divergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mean Field Approximation\n",
    "\n",
    "The mean field approximation is a common choice to restrict the distributions under consideration in variational inference.  \n",
    "\n",
    "If we partition the elements of $Z$ into $M$ disjoint groups, then the mean field approximation assumes that these distributions factor, that is that:\n",
    "$$q(Z) = \\prod_{i=1}^M q_i(Z_i).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, under the mean field approximation, we can find the distribution of the form above that maximizes the lower bound $L(q)$. (Let $q_j$ be shorthand for $q_j(Z_j)$):\n",
    "\n",
    "\\begin{aligned}\n",
    "L(q) &= \\int q(Z) \\log\\left(\\dfrac{p(X, Z)}{q(Z)}\\right)dZ \\\\ \n",
    "&= \\int \\prod_i q_i \\left(\\log p(X, Z) - \\sum_i \\log q_i\\right)dZ \\\\\n",
    "&= \\int q_j \\prod_{i\\neq j} \\left(\\log p(X, Z) - \\sum_i \\log q_i\\right)dZ \\\\\n",
    "&= \\int q_j \\prod_{i\\neq j} \\log p(X, Z)dZ - \\int q_j \\prod_{i\\neq j}\\sum_i \\log q_i dZ \\\\\n",
    "&= \\int q_j \\left(\\int \\log p(X, Z)\\prod_{i\\neq j}q_i dZ_i\\right)dZ_j - \\int q_j \\log q_j dZ_j + const. \\\\\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each $\\int q_i dZ_i$ term integrates to 1, since $q_i$ is a proability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\implies L(q) &= \\int q_j \\log \\tilde{p}(X, Z_j)dZ_j - \\int q_j\\log q_j dZ_j \\\\\n",
    "\\log \\tilde{p}(X, Z_j) &= \\mathbb{E}_{i\\neq j} \\left(\\log p(X, Z)\\right) + const. \\\\\n",
    "\\mathbb{E}_{i\\neq j} \\left(\\log p(X, Z)\\right) &= \\int p(X, Z)\\prod_{i\\neq j} q_i dZ_i\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to maximize $L(q)$ with respect to $q_j$, while holding all $q_{i\\neq j}$ fixed. This is equivalent to minimizing the KL divergence.\n",
    "\n",
    "This minimum occurs when $q_j(Z_j) = \\tilde{p}(X, Z_j)$.\n",
    "\n",
    "$$\\implies \\log q_j^*(Z_j) = \\mathbb{E}_{i\\neq j} \\left(\\log p(X, Z)\\right) + const.$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normalizing constant is usually determined by inspection.  The optimal form of $q_j^*$ depends on the values of the other $q_{i\\neq j}$, so the $q_i$ are all initalized and then cycled through, one at a time.\n",
    "\n",
    "Since the bound $L(q)$ is convex with respect to each factor $q_i$, convergence is guarenteed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimizing $KL(q||p)$ leads to distributions $q$ that tend to underestimate the variance of $p$. Likewise, for multimodal posteriors, minimizing $KL(q||p)$ will find one mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Univariate Gaussian Example\n",
    "\n",
    "As a simple example of Variational Inference in practice, we will find the approximate posteriors of the mean and precision for a univariate Gaussian.\n",
    "\n",
    "The likelihood of the data is:\n",
    "\\begin{aligned}\n",
    "p(x_{1:N} |\\mu, \\tau) &= \\prod_{n=1}^N N(x_n | \\mu, \\tau^{-1}) \\\\\n",
    "&= \\left(\\dfrac{\\tau}{2\\pi}\\right)^{N/2}\\mbox{exp}\\left(-\\dfrac{\\tau}{2} \\sum_{n=1}^N (x_n - \\mu)^2\\right)\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The priors for $\\mu$ and $\\tau$ are:\n",
    "\\begin{aligned}\n",
    "p(\\mu | \\tau) &= N(\\mu | \\mu_0, (\\lambda_0\\tau)^{-1}) \\\\\n",
    "p(\\tau) &= \\mbox{Gamma}(\\tau | a_0, b_0) \\\\\n",
    "\\end{aligned}\n",
    "\n",
    "We will assume a mean-field approximation for the approximate posterior $q$:\n",
    "$$q(\\mu, \\tau) = q_{\\mu}(\\mu)q_{\\tau}(\\tau)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, using the result that\n",
    "$$\\log q_j^*(Z_j) = \\mathbb{E}_{i\\neq j} \\left(\\log p(X, Z)\\right) + const., $$\n",
    "we can find the optimal form of $q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\log q^*_{\\mu}(\\mu) &= \\mathbb{E}_{\\tau}\\left(\\log p(x_{1:N}|\\mu, \\tau) + \\log p(\\mu |\\tau)\\right) + const. \\\\\n",
    "&= \\mathbb{E}_{\\tau}\\left(-\\dfrac{\\tau}{2}\\sum_{n=1}^N (x_n - \\mu)^2 - \\dfrac{\\lambda_0 \\tau}{2}(\\mu - \\mu_0)^2\\right) + const. \\\\\n",
    "&= -\\dfrac{\\mathbb{E}_{\\tau}(\\tau)}{2}\\left(\\lambda_0(\\mu - \\mu_0)^2 + \\sum_{n=1}^N (x_n - \\mu)^2\\right) + const. \\\\\n",
    "& = -\\dfrac{\\mathbb{E}_{\\tau}(\\tau)}{2}(\\lambda_0 + N)\\left(\\mu - \\dfrac{\\lambda_0\\mu_0 + N\\bar{x}}{\\lambda_0 + N}\\right)^2 + const. \\mbox{ (complete the square)} \\\\\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a quadratic form in the exponent, which means that $q^*_{\\mu}$ will be normally distributed:\n",
    "\\begin{aligned}\n",
    "q^*_{\\mu}(\\mu) &= N(\\mu | \\mu_N, \\lambda_N^{-1}) \\\\\n",
    "\\mu_N &= \\dfrac{\\lambda_0\\mu_0 + N\\bar{x}}{\\lambda_0 + N} \\\\\n",
    "\\lambda_N &= (\\lambda_0 + N)\\mathbb{E}(\\tau) \n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\log q^*_{\\tau}(\\tau) &= \\mathbb{E}_{\\mu}\\left(\\log p(x_{1:N} | \\mu, \\tau) + \\log p(\\mu | \\tau)\\right) + \\log p(\\tau) + const. \\\\\n",
    "&= \\mathbb{E}_{\\mu} \\left(\\frac{N}{2}\\log \\tau - \\frac{\\tau}{2}\\sum_{n=1}^N(x_N - \\mu)^2 + \\log\\tau - \\frac{\\lambda_0}{2}(\\mu - \\mu_0)^2\\tau\\right) + (a_0 - 1)\\log\\tau - b_0\\tau + const. \\\\\n",
    "&= \\left(a_0 + \\dfrac{N}{2}\\right)\\log\\tau - \\tau\\left(b_0 + \\dfrac{1}{2} \\mathbb{E}_{\\mu}\\left(\\sum_{n=1}^N (x_n - \\mu)^2 + \\lambda_0(\\mu - \\mu_0)^2\\right)\\right) + const. \\\\\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the form of the log of a Gamma distribution.  Therefore, we have that\n",
    "\n",
    "\\begin{aligned}\n",
    "q_{\\tau}(\\tau) &= \\mbox{Gamma}(\\tau | a_N, b_N) \\\\\n",
    "a_N &= a_0 + \\dfrac{N}{2} \\\\\n",
    "b_N &= b_0 + \\dfrac{1}{2} \\mathbb{E}_{\\mu} \\left(\\sum_{n=1}^N (x_n - \\mu)^2 + \\lambda_0(\\mu - \\mu_0)^2\\right)\n",
    "\\end{aligned}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the parameters $\\mu$ and $\\tau$ can be iteratively updated.  These specific forms of $q_{\\mu}$ and $q_{\\tau}$ were not specifically assumed and arose as a result of conjugate priors and the structure of the likelihood.\n",
    "\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}(\\tau) &= \\dfrac{a_N}{b_N} \\\\\n",
    "\\mathbb{E}(\\mu) &= \\mu_N \\\\\n",
    "\\mathbb{E}(\\mu^2) &= \\mathbb{E}(\\mu)^2 + \\mathbb{V}(\\mu) \\\\\n",
    "&= \\mu_N^2 + \\lambda_N^{-1} \\\\\n",
    "\\mathbb{E}_{\\mu} \\left(\\sum_{n=1}^N (x_N - \\mu)^2 + \\lambda_0(\\mu - \\mu_0)^2\\right) &= \\mathbb{E}(\\mu^2) (N + \\lambda_0) - 2\\mathbb{E}(\\mu)(N\\bar{x} + \\lambda_0\\mu_0) + \\left(\\lambda_0\\mu_0^2 + \\sum_n x_n^2\\right)\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## X is the data\n",
    "## mu0, lambda0, a0, b0 are prior hyperparameter values\n",
    "## crit is convergence criteria tolerance\n",
    "def Univariate_VI(X, mu0, lambda0, a0, b0, crit):\n",
    "    N = len(X) ## number of data points \n",
    "    \n",
    "    # Randomly initialize starting values for parameters of q\n",
    "    muN = 0\n",
    "    lambdaN = 1\n",
    "    aN = 1\n",
    "    bN = 1\n",
    "    \n",
    "    # Initialize data structures\n",
    "    ll_old = 10E10\n",
    "    ll_new = 0\n",
    "    converge = 10E10 # current difference in log likelihoods to check for convergence\n",
    "    \n",
    "    while converge > crit:\n",
    "    \n",
    "        ## (1).  Update q(mu)\n",
    "        muN = (lambda0*mu0 + N*np.mean(X))/(lambda0 + N)\n",
    "        lambdaN = (lambda0 + N)*aN/bN\n",
    "        \n",
    "            \n",
    "        ## (2). Update q(tau)\n",
    "        aN = a0 + N/2\n",
    "        Emu2 = muN**2 + 1/lambdaN ## expectation of mu^2\n",
    "        bN = b0 + 0.5*(Emu2*(N+lambda0) - 2*muN*(N*np.mean(X) + lambda0*mu0) + lambda0*mu0**2 + np.sum(X**2))\n",
    "        \n",
    "        \n",
    "        ## Check convergence criteria (log likelihood using posterior mean for parameter values)\n",
    "        ll_new = np.sum(norm(loc = muN, scale = np.sqrt(bN/aN)).pdf(X))\n",
    "        converge = abs(ll_new - ll_old)\n",
    "        ll_old = ll_new\n",
    "        #print(converge)\n",
    "        \n",
    "        \n",
    "    return(muN, lambdaN, aN, bN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate data\n",
    "tau_true = 5\n",
    "mu_true = 2\n",
    "X = np.random.normal(loc = mu_true, scale = np.sqrt(1/tau_true), size = 100)\n",
    "\n",
    "\n",
    "mu0 = 0\n",
    "lambda0 = 1\n",
    "a0 = 1\n",
    "b0 = 1\n",
    "muN, lambdaN, aN, bN = Univariate_VI(X, mu0, lambda0, a0, b0, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.998773432892913"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8705297607077496"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aN/bN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simulate values from posterior\n",
    "tau_post = np.random.gamma(shape = aN, scale = bN, size = 1000)\n",
    "mu_post = np.random.normal(muN, lambdaN, size = 1000)\n",
    "X_sim = np.random.normal(mu_post, np.sqrt(1/tau_post))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (16,8))\n",
    "plt.hist(X, alpha = 0.5, label = \"Data\")\n",
    "plt.hist(X_sim, alpha = 0.5, label = \"Posterior Draws\")\n",
    "plt.legend(loc = \"upper right\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "*Pattern Recognition and Machine Learning* by Chris Bishop (https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
